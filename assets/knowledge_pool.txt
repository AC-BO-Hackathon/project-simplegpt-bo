## Explanation of Weighted Sum Approach
"Each target variable you've specified (like maximizing yield or minimizing contaminant levels) will be assigned a weight. 
These weights indicate the relative importance of each target in our optimization process. 
If you have specific preferences on the importance of each objective, you can provide a list of weights accordingly. 
Otherwise, we'll assume all targets are equally important and assign them equal weights."

## Explanation of Tree-Parzen Estimators (TPE) Method
The Tree-Structured Parzen Estimator (TPE) is a method used primarily for optimizing hyperparameters in machine learning models. It's a type of Bayesian optimization algorithm that focuses on finding the best hyperparameters by updating its beliefs about which hyperparameters are most likely to yield optimal model performance. Here's a brief overview of how TPE operates:
Initial Sampling: TPE begins by randomly sampling hyperparameters from predefined distributions, which serves as a starting point to identify promising areas in the hyperparameter space.
Partitioning and Estimation: After evaluating the performance of models trained with the initially sampled hyperparameters, the algorithm divides the search space into regions based on performance. Specifically, it separates hyperparameters into groups that have led to better or worse performance, using a quantile threshold. For each group, it constructs Parzen window estimators (density estimators) to model the likelihood of a hyperparameter set belonging to the "good" or "bad" group.
Optimization: TPE aims to choose new hyperparameters by maximizing the expected improvement over the best observed performance so far. It does this by comparing the modeled distributions of "good" and "bad" hyperparameters, specifically looking for hyperparameters that are more likely to improve model performance. This involves a balance between exploring new areas in the search space (exploration) and refining the search around already identified promising areas (exploitation).
TPE's efficiency stems from its focus on regions of the search space that are more likely to produce better results, guided by a surrogate model (the probabilistic model built from past evaluations). By emphasizing the expected improvement, TPE navigates the search space effectively, offering a strategic approach to finding optimal hyperparameters.
The Tree-Structured Parzen Estimator (TPE) differs from other Bayesian optimization methods in how it constructs the surrogate model and selects the next hyperparameters to evaluate. Here are the key differences:
Surrogate Model Construction: TPE uses Bayes' rule to build a model based on the probability of hyperparameters given the objective function score, expressed as p(x|y). This approach differs from directly representing p(y|x) used in other methods
Selection Function: The criteria for choosing the next set of hyperparameters in TPE is based on maximizing the Expected Improvement, which involves comparing the ratio of good to bad distributions. This contrasts with other methods that may use different selection criteria like Probability of Improvement or Upper Confidence Bound
Exploration vs. Exploitation: TPE balances exploration and exploitation by drawing hyperparameters likely to improve model performance based on the surrogate function. It aims to maximize the Expected Improvement criteria, guiding the search efficiently towards better hyperparameter configurations
Efficiency: The use of Parzen Estimators in TPE allows for efficient modeling of beliefs about optimal hyperparameters and updating these beliefs as the algorithm learns from model performance. This iterative process helps TPE converge towards better hyperparameter configurations more effectively compared to some other Bayesian optimization methods
In summary, the Tree-Structured Parzen Estimator stands out for its unique approach to constructing the surrogate model, selecting hyperparameters based on Expected Improvement, and efficiently balancing exploration and exploitation during the optimization process.
